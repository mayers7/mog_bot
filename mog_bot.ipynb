{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "508a2a8a",
   "metadata": {},
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdb19ac",
   "metadata": {},
   "source": [
    "# Function to check user profiles for specific links containing keywords\n",
    "def check_user_profile(username):\n",
    "    user = reddit.redditor(username)\n",
    "    try:\n",
    "        # Check links in the user's public description\n",
    "        profile_text = user.subreddit[\"public_description\"]\n",
    "        \n",
    "        # Find all links in the profile text\n",
    "        links = re.findall(r'https?://[^\\s]+', profile_text)\n",
    "        \n",
    "        for link in links:\n",
    "            if any(keyword in link.lower() for keyword in keywords):\n",
    "                return True\n",
    "        \n",
    "        # Check links in the user's \"Links\" section (if they exist)\n",
    "        for link in user.subreddit[\"links\"]:\n",
    "            if any(keyword in link[\"url\"].lower() for keyword in keywords):\n",
    "                return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing profile of {username}: {e}\")\n",
    "    \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2202a9",
   "metadata": {},
   "source": [
    "# Monitor new posts within the last 30 minutes\n",
    "def process_new_submissions():\n",
    "    current_time = datetime.now(timezone.utc)\n",
    "    for submission in subreddit.new(limit=50):  # Fetch recent submissions\n",
    "        post_time = datetime.fromtimestamp(submission.created_utc, tz=timezone.utc)\n",
    "        time_difference = (current_time - post_time).total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "        print(f\"Post: {submission.title}, Time difference: {time_difference} minutes\")\n",
    "\n",
    "        if time_difference > 1440:  # Skip posts older than 30 minutes\n",
    "            continue\n",
    "\n",
    "        author = submission.author.name\n",
    "        print(f\"Checking user: {author}\")  # Debugging line\n",
    "\n",
    "        if check_user_profile(author):  # Check for links with specific keywords\n",
    "            print(f\"Reporting: {author}\")  # Debugging line\n",
    "            report_reason = \"Mog_bot: Test, please ignore this report.\"\n",
    "            submission.report(report_reason)  # Report the post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1f4b82",
   "metadata": {},
   "source": [
    "process_new_submissions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da46c892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283f28c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying this using scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "632c5906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melis\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\melis\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\melis\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json  # Add this line at the top of your code\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47c7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2) #keeps us from hitting reddit API limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a85a4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit API Credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"lAofMRkJRtAKcZUW3ulyYg\",\n",
    "    client_secret=\"xbwAawh2qDnY82DFy8E9K22B1vNo4Q\",\n",
    "    user_agent=\"mog_bot\",\n",
    "    username=\"mog_bot\",\n",
    "    password=\"kupopo123\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "840c9c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subreddit\n",
    "subreddit_name = \"finalfantasy\"\n",
    "subreddit = reddit.subreddit(subreddit_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fab2e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as: mog_bot\n"
     ]
    }
   ],
   "source": [
    "print(f\"Logged in as: {reddit.user.me()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66969559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the domain name from a URL\n",
    "def extract_domain(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    return parsed_url.netloc  # Extract just the domain (e.g., www.amazon.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ab840cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check user profiles for links in the \"Links\" section\n",
    "def check_user_profile(username):\n",
    "    # Send an HTTP request to fetch the user's profile page\n",
    "    user_profile_url = f\"https://www.reddit.com/user/{username}\"\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    try:\n",
    "        response = requests.get(user_profile_url, headers=headers)\n",
    "        \n",
    "        # If the request was successful\n",
    "        if response.status_code == 200:\n",
    "            print(f\"Successfully fetched profile for u/{username}.\")\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Look for all <faceplate-tracker> elements with the 'social_link' noun\n",
    "            faceplate_elements = soup.find_all('faceplate-tracker', {'noun': 'social_link'})\n",
    "            \n",
    "            # List to store the extracted links\n",
    "            found_links = []\n",
    "\n",
    "            for faceplate in faceplate_elements:\n",
    "                # Extract the JSON data from the 'data-faceplate-tracking-context' attribute\n",
    "                tracking_data = faceplate.get('data-faceplate-tracking-context')\n",
    "\n",
    "                if tracking_data:\n",
    "                    # Parse the JSON data to extract the URL\n",
    "                    try:\n",
    "                        tracking_json = json.loads(tracking_data)\n",
    "                        social_link = tracking_json.get('social_link', {})\n",
    "                        url = social_link.get('url')\n",
    "                        \n",
    "                        if url:\n",
    "                            # Shorten the URL to just the domain name\n",
    "                            domain = extract_domain(url)\n",
    "                            found_links.append(domain)\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"Error decoding JSON for u/{username}: {e}\")\n",
    "            \n",
    "            # If links are found, report them\n",
    "            if found_links:\n",
    "                print(f\"Links found in u/{username}'s profile: {found_links}\")\n",
    "                # Construct the report with the found links, limiting it to under 100 characters\n",
    "                report_reason = f\"Mog_bot: User profile links found: {', '.join(found_links[:5])}.\"\n",
    "                return report_reason  # Return the report message with links (limiting to 5 domains if needed)\n",
    "            else:\n",
    "                print(f\"No 'social_link' found in u/{username}'s profile.\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"Failed to retrieve profile for u/{username}. HTTP status code: {response.status_code}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error accessing profile of {username}: {e}\")\n",
    "    \n",
    "    return None  # Return None if no report is generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72e7a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the report was successfully made by logging the submission ID and report reason\n",
    "def process_new_submissions():\n",
    "    current_time = datetime.now(timezone.utc)\n",
    "    for submission in subreddit.new(limit=10):  # Fetch recent submissions\n",
    "        post_time = datetime.fromtimestamp(submission.created_utc, tz=timezone.utc)\n",
    "        time_difference = (current_time - post_time).total_seconds() / 60  # Convert to minutes\n",
    "\n",
    "        print(f\"Processing submission: {submission.title} by {submission.author.name} at {post_time}\")\n",
    "\n",
    "        if time_difference > 120:  # Skip posts older than 30 minutes\n",
    "            continue\n",
    "\n",
    "        author = submission.author.name\n",
    "        try:\n",
    "            report_reason = check_user_profile(author)  # Check for links in profile\n",
    "            if report_reason:  # If links are found, report the post\n",
    "                print(f\"Reporting post: {submission.title}\")\n",
    "                result = submission.report(report_reason)  # Attempt to report the post\n",
    "                if result is None:  # If result is None, report was successful\n",
    "                    print(f\"Reported: {author} - {report_reason}\")\n",
    "                else:\n",
    "                    print(f\"Failed to report: {author}. Result: {result}\")\n",
    "            else:\n",
    "                print(f\"No report reason for u/{author}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing submission {submission.id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26ebfb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing submission: test post please ignore 2 by FF_TEST_ACCOUNT at 2025-03-16 23:46:48+00:00\n",
      "Successfully fetched profile for u/FF_TEST_ACCOUNT.\n",
      "Links found in u/FF_TEST_ACCOUNT's profile: ['twitter.com']\n",
      "Reporting post: test post please ignore 2\n",
      "Reported: FF_TEST_ACCOUNT - Mog_bot: User profile links found: twitter.com.\n",
      "Processing submission: another test post sorry by FF_TEST_ACCOUNT at 2025-03-16 23:47:32+00:00\n",
      "Successfully fetched profile for u/FF_TEST_ACCOUNT.\n",
      "Links found in u/FF_TEST_ACCOUNT's profile: ['twitter.com']\n",
      "Reporting post: another test post sorry\n",
      "Reported: FF_TEST_ACCOUNT - Mog_bot: User profile links found: twitter.com.\n",
      "Processing submission: test post please ignore by FF_TEST_ACCOUNT at 2025-03-16 23:44:14+00:00\n",
      "Successfully fetched profile for u/FF_TEST_ACCOUNT.\n",
      "Links found in u/FF_TEST_ACCOUNT's profile: ['twitter.com']\n",
      "Reporting post: test post please ignore\n",
      "Reported: FF_TEST_ACCOUNT - Mog_bot: User profile links found: twitter.com.\n",
      "Processing submission: First impressions of Final Fantasy XVI by jgfelix at 2025-03-16 23:15:35+00:00\n",
      "Successfully fetched profile for u/jgfelix.\n",
      "No 'social_link' found in u/jgfelix's profile.\n",
      "No report reason for u/jgfelix\n",
      "Processing submission: For Final Fantasy X and X-2, which do you think is the better experience: the PS2 originals, or the Remasters? by SugarSmoothie at 2025-03-16 22:45:02+00:00\n",
      "Successfully fetched profile for u/SugarSmoothie.\n",
      "No 'social_link' found in u/SugarSmoothie's profile.\n",
      "No report reason for u/SugarSmoothie\n",
      "Processing submission: Please help me understand the combat system by Zeznon at 2025-03-16 22:26:20+00:00\n",
      "Successfully fetched profile for u/Zeznon.\n",
      "No 'social_link' found in u/Zeznon's profile.\n",
      "No report reason for u/Zeznon\n",
      "Processing submission: Help with FFXII's Gambit system by LeandroRN91 at 2025-03-16 20:27:46+00:00\n",
      "Processing submission: Strangers of Paradise fans, help! by Zachbustems at 2025-03-16 19:24:03+00:00\n",
      "Processing submission: I was listening to Dancing Mad at my job and then I was sleep deprived drawing this. Hope you all enjoy it :) by ElAlca at 2025-03-16 19:04:15+00:00\n",
      "Processing submission: Before I purchase FFXVI by Vapor_Visions_533 at 2025-03-16 18:50:16+00:00\n"
     ]
    }
   ],
   "source": [
    "process_new_submissions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e7a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send a GET request to the user's profile page\n",
    "user_profile_url = \"https://www.reddit.com/user/ItsWhimsicalSage/\"\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "response = requests.get(user_profile_url, headers=headers)\n",
    "\n",
    "# If the request is successful, print the HTML content\n",
    "if response.status_code == 200:\n",
    "    print(response.text)  # This will output the raw HTML, look for the \"Links\" section\n",
    "else:\n",
    "    print(f\"Failed to fetch profile. HTTP status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8f9ecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report the newest post\n",
    "def report_newest_post():\n",
    "    # Fetch the newest post\n",
    "    submission = next(subreddit.new(limit=1))  # Get the most recent post\n",
    "    \n",
    "    print(f\"Reporting post: {submission.title} by {submission.author}\")\n",
    "    \n",
    "    # Report the post with a reason\n",
    "    submission.report(reason=\"This is a test report for the newest post.\")\n",
    "    \n",
    "    print(f\"Reported post: {submission.title} with reason: 'This is a test report for the newest post.'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60e925eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporting post: First impressions of Final Fantasy XVI by jgfelix\n",
      "Reported post: First impressions of Final Fantasy XVI with reason: 'This is a test report for the newest post.'\n"
     ]
    }
   ],
   "source": [
    "#this report does show up in queue\n",
    "report_newest_post()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e0983f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
